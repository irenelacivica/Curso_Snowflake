# Tablas din√°micas

Las tablas din√°micas son una funci√≥n relativamente nueva de Snowflake dise√±ada para **actualizar autom√°ticamente los conjuntos de datos derivados a medida que cambian los datos subyacentes.** Estas tablas est√°n pensadas para reducir la sobrecarga de mantenimiento de los conjuntos de datos que necesitan mantenerse actualizados con los datos base de los que derivan.

¬øD√≥nde hab√≠amos visto esto? Cuando estuvimos viendo los Task, tambi√©n hac√≠amos actualizaciones de los datos de las tablas. Entonces, ¬øcu√°ndo utilizo una tarea y cuando una tabla din√°mica?:

- Las Task son m√°s adecuadas para escenarios en los que se necesita un control sobre cu√°ndo y c√≥mo se ejecutan los procesos de datos, especialmente para operaciones son continuas basadas en intervalos.
- Las tablas din√°micas son perfectas para cuando necesitamos que un conjunto de datos siempre se encuentre en su forma m√°s actualizada, sin necesidad de activar manualmente dichas actualizaciones.


# üîî Nueva tarea

¬°Sorpresa! Aunque todo parec√≠a estar listo y en funcionamiento, siempre hay cambios por hacer. Esto refleja una realidad muy importante en el manejo de datos: los flujos de datos **NUNCA SE TERMINAN**.

Vamos a ver las tareas que se necesitan realizar utilizando Snowflake y las tablas din√°micas:

Tu equipo ha o√≠do hablar de las tablas din√°micas y espera que utilices estas tablas din√°micas para gestionar todo el flujo de datos, desde la captura inicial (Bronze) hasta las transformaciones intermedias (Silver) y finalmente la refinaci√≥n hacia los datos de alta calidad (Gold).

## 1. ¬øC√≥mo est√° montado actualmente nuestro flujo de datos?

### a) Capa Silver

Este proceso actualmente est√° implementado mediante un procedimiento almacenado, pero ahora queremos cambiarlo por tablas din√°micas. 

```sql
--- CARGAR SILVER
CREATE OR REPLACE PROCEDURE MYDB.SILVER.INSERT_PROCEDURE_SILVER()
    RETURNS VARCHAR
    LANGUAGE SQL
    EXECUTE AS CALLER
AS
BEGIN

    -- ORDERS
    INSERT INTO MYDB.SILVER.ORDERS 
    SELECT 
        ORDER_ID::varchar(50),
        SHIPPING_SERVICE::varchar(20),
        (replace(SHIPPING_COST,',','.'))::decimal,
        ADDRESS_ID::varchar(50),
        CREATED_AT::timestamp_ntz,
        IFNULL(promo_id,'N/A'),
        ESTIMATED_DELIVERY_AT::timestamp_ntz,
        (replace(ORDER_COST,',','.'))::decimal,
        USER_ID::varchar(50),
        (replace(ORDER_TOTAL,',','.'))::decimal,
        DELIVERED_AT::timestamp_ntz,
        TRACKING_ID::varchar(50),
        STATUS::varchar(20),
        TIMESTAMPDIFF(HOUR,created_at,delivered_at)
    FROM curso_snowflake_de_2023.bronze.orders_hist;
    
    -- EVENTS
    INSERT INTO MYDB.SILVER.EVENTS 
    SELECT 
        EVENT_ID::varchar(50),
        PAGE_URL::varchar(200),
        EVENT_TYPE::varchar(50),
        USER_ID::varchar(50),
        PRODUCT_ID::varchar(50),
        SESSION_ID::varchar(50),
        CREATED_AT::timestamp_ntz,
        ORDER_ID::varchar(50),
        ROW_NUMBER() OVER (PARTITION BY session_id ORDER BY created_at ASC)
    FROM MYDB.bronze.events;
    
    -- PRODUCTS
    INSERT INTO MYDB.SILVER.PRODUCTS
    SELECT 
        PRODUCT_ID::Varchar(50),
        (replace(PRICE,',','.'))::decimal,
        NAME::varchar(100),
        INVENTORY::number(38,0)
    FROM MYDB.bronze.products_original;
    
    -- ADDRESSES
    INSERT INTO MYDB.SILVER.ADDRESSES 
    SELECT 
        ADDRESS_ID::varchar(50),
        ZIPCODE::number(38,0),
        COUNTRY::varchar(50),
        ADDRESS::varchar(150),
        STATE::varchar(50)
    FROM MYDB.bronze.addresses;
    
    -- USERS
    INSERT INTO MYDB.SILVER.USERS 
    SELECT 
        USER_ID::varchar(50),
        UPDATED_AT::timestamp_ntz,
        ADDRESS_ID::varchar(50),    
        LAST_NAME::varchar(50),
        CREATED_AT::timestamp_ntz,
        PHONE_NUMBER::varchar(20),
        FIRST_NAME::varchar(50),
        EMAIL::varchar(100)
    FROM MYDB.bronze.users;
    
    -- ORDER_ITEMS
    INSERT INTO MYDB.SILVER.ORDER_ITEMS 
    SELECT 
        ORDER_ID::varchar(50),
        PRODUCT_ID::varchar(50),
        QUANTITY::number(38,0)
    FROM MYDB.bronze.order_items;
    
    -- PROMOS
    INSERT INTO MYDB.SILVER.PROMOS 
    SELECT 
        PROMO_ID::varchar(50),
        DISCOUNT::float,
        STATUS::varchar(50)
    FROM MYDB.bronze.promos;    

    RETURN 'Insertado con √©xito m√°quina';
END;

```

## **b) Capa Gold**

Dentro de la capa Gold tenemos dos procedimientos que utilizamos para que precalculen datos espec√≠ficos y nosotros podemos usar estos datos en cuadros de mando:

1. **Procedimiento para detalles de sesi√≥n de Gold:** agrupamos los datos de eventos en la tabla Silver, para cada sesi√≥n identificada por **`session_id`** , indic√°ndose si la sesi√≥n result√≥ en un pedido o no, el m√°ximo n√∫mero de interacciones dentro de la sesi√≥n y la diferencia en minutos entre el primer y el √∫ltimo evento registrado en la sesi√≥n.

```sql
---- GOLD SESSION DETAILS
CREATE OR REPLACE PROCEDURE MYDB.GOLD.INSERT_GOLD_SESSION_DETAILS()
    RETURNS VARCHAR
    LANGUAGE SQL
    EXECUTE AS CALLER
AS
BEGIN
    
    -- SESSION_DETAILS
    INSERT INTO MYDB.GOLD.session_details 
    SELECT 
        session_id,
        CASE WHEN MAX(order_id) IS NULL THEN FALSE ELSE TRUE END,
        MAX(hit_number),
        TIMESTAMPDIFF(MINUTE,MIN(created_at),MAX(created_at))
    FROM MYDB.SILVER.events 
    GROUP BY session_id;
    
    RETURN 'Insertado con √©xito m√°quina';
END;
```

2. **Procedimiento para An√°lisis del Estado en Gold:** realiza un an√°lisis por estado sobre los datos de √≥rdenes y direcciones de la capa Silver, utilizando una agrupaci√≥n por estado, una suma del costo de pedidos por estado y un conteo de pedidos y usuarios √∫nicos por estado.

```sql
CREATE OR REPLACE PROCEDURE MYDB.GOLD.INSERT_GOLD_STATE_ANALYSIS()
    RETURNS VARCHAR
    LANGUAGE SQL
    EXECUTE AS CALLER
AS
BEGIN
    -- GENERAL_STATE_ANALYSIS
    INSERT INTO MYDB.GOLD.GENERAL_STATE_ANALYSIS 
    SELECT 
        a.state,
        SUM(o.order_cost),
        COUNT(*),
        COUNT(DISTINCT o.user_id),
        ROUND(SUM(o.shipping_cost)/SUM(o.order_total),2),
        mode(shipping_service)
    FROM MYDB.SILVER.ORDERS o 
    LEFT JOIN MYDB.SILVER.ADDRESSES a ON o.address_id = a.address_id 
    GROUP BY a.state;
    RETURN 'Insertado con √©xito m√°quina';
END;

```

## 2. Tu tarea de crear tablas din√°micas con el flujo de datos antiguo

### a) Capa Silver

En esta etapa, debes crear 7 tablas din√°micas para procesar de manera autom√°tica e incremental los datos que llegan a las tablas de bronze de la base de datos centralizada (**curso_snowflake_de_2024**). Utilizar√°s el warehouse WH_BASICO y deber√°s configurar un retraso de procesamiento (lag) de 1 minuto.

Coge las tablas que tenemos actualmente en Silver y modif√≠calas para que sean tablas din√°micas.

Os dejamos un atajo a la documentaci√≥n https://docs.snowflake.com/en/user-guide/dynamic-tables-tasks-create

### b) Capa Gold

Finalmente, la etapa Gold tambi√©n necesita de tablas din√°micas. Estas tablas se actualizar√°n en respuesta a cambios en las tablas de Silver, utilizando un "lag" configurado como DOWNSTREAM. 

Coge las tablas que tenemos actualmente en Gold y modif√≠calas para que sean tablas din√°micas.

## 3. Tarea extra

¬°Tu equipo no te deja que descanses ü•µ! El negocio tiene claro el dato que le gustar√≠a consultar en un cuadro de mando, y para el que t√∫ deber√≠as de preparar dos agrupados que ya precalculen esta informaci√≥n. Cada uno de ellos tambi√©n ser√°n una tabla din√°mica. En este caso, el lag deberemos configurarlo como DOWNSTREAM, de esta forma estas tablas din√°micas se actualizar√°n cuando lo hagan las de Silver. 

1. Suma de Shipping_Cost agrupada por C√≥digo Postal: Deber√°s crear una tabla din√°mica que realice este c√°lculo.
2. Suma de Order_Cost por Nombre de Producto d√≥nde el estado de la orden sea "shipped‚Äù: Igualmente, deber√°s crear una tabla din√°mica para este c√°lculo.

</br>
</br>

# Snowpark

Snowpark¬†proporciona una biblioteca intuitiva para consultar y procesar datos a escala en¬†Snowflake.¬†Mediante una biblioteca, puedes crear aplicaciones que procesen datos en¬†Snowflake¬†**sin mover los datos al sistema¬†donde se ejecuta el c√≥digo de su aplicaci√≥n**.

Snowflake¬†proporciona actualmente bibliotecas¬†Snowpark¬†para tres lenguajes:¬†**Java, Python y Scala**.

En este caso, vamos a poner un ejemplo con Python, y ¬øpor qu√© con Python? Porque Snowflake nos permite utilizar un Worksheet con Python directamente, sin tener que instalar nada y desde la propia interfaz de Snowflake:

![Untitled (4)](https://github.com/javipo84/Curso_Snowflake/assets/166698078/d1ffc4b4-a805-422a-a23c-584492db42e1)


# **1. Configuraci√≥n inicial**

Vamos a hacer un clone de nuestra tabla de orders para poder modificarla sin problema:

```sql
CREATE OR REPLACE TABLE BASE_DE_DATOS_ALUMNO.BRONZE.ORDERS_COPY 
  CLONE BASE_DE_DATOS_ALUMNO.BRONZE.ORDERS;
```

# **2. Creaci√≥n y visualizaci√≥n de un dataframe**

Primero, crearemos un dataframe simple desde una tabla existente en tu base de datos y veremos c√≥mo mostrar los resultados.

```sql
import snowflake.snowpark as snowpark

def main(session: snowpark.Session): 
    # Seleccionamos la tabla desde tu esquema y base de datos
    df = session.table("BASE_DE_DATOS_ALUMNO.BRONZE.ORDERS_COPY")
    return df
```

Para mostrar los resultados, podemos verlos tambi√©n desde la terminal. Esto se har√° seleccionando que la salida sea un String y usando la funci√≥n print de python:

![Untitled (3)](https://github.com/javipo84/Curso_Snowflake/assets/166698078/8d92bd53-3489-4117-99b9-c8cbff135b11)


```sql
import snowflake.snowpark as snowpark

def main(session: snowpark.Session):
    session.use_database('BASE_DE_DATOS_ALUMNO')
    session.use_schema('BRONZE')

    # Creamos un dataframe
    df = session.table("ORDERS_COPY")
    print("df.show(10) resultado")
    print(df.show(10))
    print('')
    print('___________________________')
    print('___________________________')
    print("df.count() resultado")
    print(df.count())
    return df
```

Para que nos vuelva a salir como tabla en la pesta√±a de ‚ÄúResults‚Äù tenemos que volver a selecciona en Settings>Return type>`Table()` :

![Untitled (2)](https://github.com/javipo84/Curso_Snowflake/assets/166698078/18976eb7-97df-45cb-98a1-c75cbd3e5144)


# 3. Transformaci√≥n de los datos

Con Python podemos escoger las columnas que queremos consultar dentro del dataframe creado:

```sql
import snowflake.snowpark as snowpark

def main(session: snowpark.Session):
    session.use_database('BASE_DE_DATOS_ALUMNO')
    session.use_schema('BRONZE')

    df = session.table("ORDERS_COPY")
    # Seleccionamos algunas columnas de inter√©s
    df = df.select("ORDER_ID", "CUSTOMER_ID", "ORDER_STATUS", "ORDER_DATE").limit(10)
    return df
```

## a) Filtrado de filas

Podemos filtrar por filas:

```sql
import snowflake.snowpark as snowpark
import snowflake.snowpark.functions as f

def main(session: snowpark.Session):
    session.use_database('BASE_DE_DATOS_ALUMNO')
    session.use_schema('BRONZE')

    df = session.table("ORDERS_COPY")
    # Filtramos las √≥rdenes con estado 4
    df = df.filter(f.col("ORDER_STATUS") == 4).limit(10)
    return df

```

## **b) Inserci√≥n de nuevas columnas**

Tambi√©n podemos agregar una columna que indique el n√∫mero de d√≠as que tard√≥ el env√≠o desde la fecha de pedido hasta la fecha de env√≠o.

```sql
import snowflake.snowpark as snowpark
import snowflake.snowpark.functions as f

def main(session: snowpark.Session):
    session.use_database('BASE_DE_DATOS_ALUMNO')
    session.use_schema('BRONZE')

    df = session.table("ORDERS_COPY")
    # Calculamos los d√≠as entre el pedido y el env√≠o
    df = df.with_column("SHIPPING_DELAY", f.datediff("SHIPPED_DATE", "ORDER_DATE"))
    return df

```

## c) Agregaci√≥n de datos

Nuestros datos tambi√©n pueden ser agrupados como si estuvi√©semos haciendo un `GROUP BY` en SQL pero en este caso con Python:

```sql
import snowflake.snowpark as snowpark
import snowflake.snowpark.functions as f

def main(session: snowpark.Session):
    session.use_database('BASE_DE_DATOS_ALUMNO')
    session.use_schema('BRONZE')

    df = session.table("ORDERS_COPY")
    # Agrupamos por STORE_ID y realizamos varias agregaciones en ORDER_TOTAL
    grouped_data = df.groupBy("STORE_ID").agg(
        f.sum("ORDER_TOTAL").as_("TOTAL_SALES"),
        f.avg("ORDER_TOTAL").as_("AVERAGE_SALES"),
        f.min("ORDER_TOTAL").as_("MIN_SALES"),
        f.max("ORDER_TOTAL").as_("MAX_SALES"),
        f.count("*").as_("COUNT_ORDERS")
    )

    return grouped_data
```

## d) **Uniones entre tablas**

Supongamos que queremos unir la tabla **`orders`** con **`customers`** donde queremos mantener todos los registros de **`orders`** y solo los datos coincidentes de **`customers`**.

```sql
import snowflake.snowpark as snowpark

def main(session: snowpark.Session):
    session.use_database('BASE_DE_DATOS_ALUMNO')
    session.use_schema('BRONZE')

    df_orders = session.table("ORDERS_COPY")
    df_customers = session.table("customers")
    # Realizamos un left join
    left_join_data = df_orders.join(df_customers, df_orders["CUSTOMER_ID"] == df_customers["CUSTOMER_ID"], "left")
    
    return left_join_data
```

## **e) Ejercicio: creaci√≥n de una columna de correo electr√≥nico para el cliente**

Generemos una direcci√≥n de correo electr√≥nico ficticia para el cliente utilizando su **`CUSTOMER_ID`**.

<details>
<summary>Soluci√≥n:</summary>
<br>
```sql import snowflake.snowpark as snowpark
        import snowflake.snowpark.functions as f
        from snowflake.snowpark.types import StringType

    def main(session: snowpark.Session):
        session.use_database('BASE_DE_DATOS_ALUMNO')
        session.use_schema('BRONZE')

    df = session.table("ORDERS_COPY")
    # Creamos una direcci√≥n de email ficticia para el cliente
    df = df.with_column('CUSTOMER_EMAIL', f.concat(f.cast(f.col("CUSTOMER_ID"), StringType()), f.lit('@example.com')))
    return df ```
</details>
